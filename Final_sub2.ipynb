{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afb47cc3",
   "metadata": {},
   "source": [
    "# Semantic Search Engine using average w2v and Sbert Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7b83a1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **Custom similarity metric: 0.5* Sbert_cosine_sim + 0.3* W2v_cosine_sim + 0.2* Normalized_Score**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55232084",
   "metadata": {},
   "source": [
    "- On following basis weight selection hase been done:-\n",
    "\n",
    "- Custom w2v is trained on this data so certaily it provides some value, so 0.3 weightage has been given.\n",
    "- Sbert overcomes the limiation of avg w2v of loosing order of sequence and gave best results among all our experiments so more weightage is given.\n",
    "- Higher the question score, more likely to be answered or can contain more answers, so 0.2 weightage has been assigned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a88621",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f323fd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import bs4\n",
    "import swifter\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import Word2Vec\n",
    "import joblib\n",
    "from tqdm import tqdm \n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6038b672",
   "metadata": {},
   "source": [
    "### Preprocessing and embedding fucntions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e8bd166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/a/47091490/4084039\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "\n",
    "\n",
    "def text_preprocessing(text):\n",
    "    '''This function does text preprocessing \n",
    "       It includes removal of html tags,\n",
    "       converting to lowercase, \n",
    "       decontraction and \n",
    "       removal of any non alphanumeric characters.\n",
    "       \n",
    "       Function takes one parameter - text\n",
    "       returns - preprocessed text\n",
    "    '''\n",
    "    \n",
    "    # Some titles (~42) start with '<' but doesnt have closing '>'. \n",
    "    #eg: #text = '<asp: RegularExpressionValidator and RegexOptions.IgnorePatternWhitespace'\n",
    "    # beautifulsoup gives emppty string on such text so remove '<' before removing html tags from titles.\n",
    "    text = text.replace(\"<\",\"\")\n",
    "    # Remove html tags from question corpus\n",
    "    text = bs4.BeautifulSoup(text, 'lxml').get_text()\n",
    "    # Convert each word to lowercase\n",
    "    text = text.lower()\n",
    "    # text decontraction. eg: won't to will not. Can't to cannot\n",
    "    text = decontracted(text)\n",
    "    # Remove any non-alphanumeric characters if present\n",
    "    text = re.sub(\"[^a-zA-Z'.+# ]+\", '', text) # kepping + for c++, . for .net, vb.net etc, # for C#\n",
    "\n",
    "    # why lemmatization is choose over stemming\n",
    "    #https://stackoverflow.com/questions/1787110/what-is-the-difference-between-lemmatization-vs-stemming\n",
    "    # Lemmatization   \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "def get_w2v_embedding(sentence):\n",
    "    '''Get 300 dim word embedding for each word from custom trained w2v model.\n",
    "       Avg word embedding to create sentence embedding\n",
    "       \n",
    "       Function accepts only one parameter - sentence (text input)\n",
    "       returns - 300 dim sentence embedding'''\n",
    "    \n",
    "    custom_w2v = []\n",
    "    stop_words = stopwords.words('english')\n",
    "    for word in sentence.split():\n",
    "        if (word not in stop_words):\n",
    "            try:\n",
    "                custom_w2v.append(loaded_model.wv[word]) #keyerror\n",
    "            except:\n",
    "                pass\n",
    "         \n",
    "    avg_w2v = np.array(custom_w2v).mean(axis=0)\n",
    "    return avg_w2v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682131e3",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97b7b137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999348, 3)\n",
      "CPU times: user 353 ms, sys: 136 ms, total: 489 ms\n",
      "Wall time: 488 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = joblib.load('deployment/cleaned_df.pkl')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4e5d97",
   "metadata": {},
   "source": [
    "### Trained Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88f955d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.8 s, sys: 1.93 s, total: 38.8 s\n",
      "Wall time: 38.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loaded_model = Word2Vec.load(\"deployment/word2vec_v2.model\")\n",
    "sentence_embedder = joblib.load('deployment/sentence_embedder.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7ea11b",
   "metadata": {},
   "source": [
    "### Pre-trained embedding loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95c976ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 362 ms, sys: 1.11 s, total: 1.47 s\n",
      "Wall time: 1.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v_embeddings = joblib.load('deployment/w2v_embeddings.pkl')\n",
    "sbert_embeddings = joblib.load('deployment/sbert_embeddings.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34819fb6",
   "metadata": {},
   "source": [
    "### Function to retrieve semantically similar questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6836c7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_1(query):\n",
    "    ''' Function to accept user query and show top 5 similar question alongwith custom score.\n",
    "        Function accepts one parameter: query (text input)\n",
    "        Processing: Text preprocessing of query, \n",
    "                    compute sentence embedding with avg w2v and sbert method,\n",
    "                    compute custom weighted score with formula 0.5*Sbert_cosine_sim + 0.3*W2v_cosine_sim + 0.2*Normalized_Score\n",
    "        Returns: None, prints similar question's titles and custom score obtained.\n",
    "    '''\n",
    "    \n",
    "    # Preprocessing input query\n",
    "    preprocessed_query = text_preprocessing(query) \n",
    "    \n",
    "    # Converting query to embedding\n",
    "    query_embedding_w2v = get_w2v_embedding(preprocessed_query)\n",
    "    query_embedding_sbert = sentence_embedder.encode(preprocessed_query, convert_to_tensor=True)\n",
    "\n",
    "    # Finding cosine similarity\n",
    "    df['Sbert_cosine_sim'] = util.pytorch_cos_sim(query_embedding_sbert, sbert_embeddings)[0]\n",
    "    df['W2v_cosine_sim'] = cosine_similarity(np.array(query_embedding_w2v).reshape(1, -1),np.array(w2v_embeddings)).T\n",
    "\n",
    "    # Computing custom similarity score\n",
    "    df['Final_Similarity Score'] = (0.5*df['Sbert_cosine_sim']) + (0.3*df['W2v_cosine_sim']) + (0.2*df['Normalized_Score'])\n",
    "    # Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "\n",
    "    sorted_df = df.sort_values(by='Final_Similarity Score', ascending=False)\n",
    "    return sorted_df[['Title','Final_Similarity Score']].head()\n",
    "\n",
    "\n",
    "\n",
    "def display_result(result_df):\n",
    "    '''\n",
    "    Funtion to display results in proper format\n",
    "    Input: result set object\n",
    "    Returns: None, displays result.\n",
    "    '''\n",
    "    print(\"\\nTop 5 most similar questions in corpus:\")\n",
    "       \n",
    "    for i in range(0,5):\n",
    "        print(\"{}) \".format(i+1), result_df['Title'].iloc[i], \"(Score: {:.4f})\".format(result_df['Final_Similarity Score'].iloc[i]))\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6abf822",
   "metadata": {},
   "source": [
    "#### Note: Final Function-2 not applicable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07c2b29",
   "metadata": {},
   "source": [
    "### Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da109bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: python sort dictionary\n",
      "\n",
      "Top 5 most similar questions in corpus:\n",
      "1)  Python: sort this dictionary (dict in dict) (Score: 0.7410)\n",
      "2)  sort a dictionary according to their values in python (Score: 0.7297)\n",
      "3)  Sort by key of dictionary inside a dictionary in Python (Score: 0.7258)\n",
      "4)  Sorting dictionary keys in python (Score: 0.7206)\n",
      "5)  Dictionary sort? (Score: 0.7203)\n",
      "CPU times: user 3.69 s, sys: 1.09 s, total: 4.78 s\n",
      "Wall time: 2.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query = 'python sort dictionary'\n",
    "result = final_fun_1(query)\n",
    "print(\"Query:\", query)\n",
    "display_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64675c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: CSS Performance\n",
      "\n",
      "Top 5 most similar questions in corpus:\n",
      "1)  CSS Performance (Score: 0.8013)\n",
      "2)  CSS Performance (Score: 0.8013)\n",
      "3)  CSS Performance Question (Score: 0.7134)\n",
      "4)  CSS Performance issues (Score: 0.7092)\n",
      "5)  Performance, serve all CSS at once, or as its needed? (Score: 0.6370)\n",
      "CPU times: user 3.8 s, sys: 1.11 s, total: 4.91 s\n",
      "Wall time: 2.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query = 'CSS Performance'\n",
    "result = final_fun_1(query)\n",
    "print(\"Query:\", query)\n",
    "display_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be36b109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: python convert date to datetime\n",
      "\n",
      "Top 5 most similar questions in corpus:\n",
      "1)  Convert date to datetime in Python (Score: 0.8058)\n",
      "2)  Convert date Python (Score: 0.7377)\n",
      "3)  How can I convert the time in a datetime string from 24:00 to 00:00 in Python? (Score: 0.7100)\n",
      "4)  Convert DateTime to Date (Score: 0.6998)\n",
      "5)  How do I convert a datetime to date? (Score: 0.6989)\n",
      "CPU times: user 3.61 s, sys: 1.13 s, total: 4.74 s\n",
      "Wall time: 2.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query= 'python convert date to datetime'\n",
    "result = final_fun_1(query)\n",
    "print(\"Query:\", query)\n",
    "display_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "418837f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: how to create list of lists in python\n",
      "\n",
      "Top 5 most similar questions in corpus:\n",
      "1)  Creating lists of lists in a pythonic way (Score: 0.7334)\n",
      "2)  List of Lists in python? (Score: 0.7226)\n",
      "3)  How to create nested lists in python? (Score: 0.7149)\n",
      "4)  Lists in Python (Score: 0.7075)\n",
      "5)  Python creating a dictionary of lists (Score: 0.6978)\n",
      "CPU times: user 3.6 s, sys: 1.19 s, total: 4.79 s\n",
      "Wall time: 2.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query = 'how to create list of lists in python'\n",
    "result = final_fun_1(query)\n",
    "print(\"Query:\", query)\n",
    "display_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f7c6c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: pd.melt() not working python\n",
      "\n",
      "Top 5 most similar questions in corpus:\n",
      "1)  I am getting an error when trying to use melt() on a dataframe containing Dates (Score: 0.4897)\n",
      "2)  Running Panda3D on Python 2.6 (Score: 0.4865)\n",
      "3)  Python .pth Files Aren't Working (Score: 0.4837)\n",
      "4)  Python pdb not breaking in files properly? (Score: 0.4795)\n",
      "5)  Python optparse not working for me (Score: 0.4749)\n",
      "CPU times: user 3.63 s, sys: 1.11 s, total: 4.74 s\n",
      "Wall time: 2.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query ='pd.melt() not working python'\n",
    "result = final_fun_1(query)\n",
    "print(\"Query:\", query)\n",
    "display_result(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d3e7a1",
   "metadata": {},
   "source": [
    "### Code queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "798c492a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: try: 22/0 except Exception as e:print(\"Error! Code: {c}, Message, {m}\".format(c = e.code, m = str(e))\n",
      "\n",
      "Top 5 most similar questions in corpus:\n",
      "1)  Exception message (Python 2.6) (Score: 0.5633)\n",
      "2)  Format Exception error (Score: 0.5628)\n",
      "3)  Exception Error in the Code (Score: 0.5612)\n",
      "4)  complus Exception code -532462766 (Score: 0.5557)\n",
      "5)  uncatchable exception from unreachable code (Score: 0.5432)\n",
      "CPU times: user 3.72 s, sys: 1.11 s, total: 4.83 s\n",
      "Wall time: 2.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query = 'try: 22/0 except Exception as e:print(\"Error! Code: {c}, Message, {m}\".format(c = e.code, m = str(e))'\n",
    "result = final_fun_1(query)\n",
    "print(\"Query:\", query)\n",
    "display_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a52c10b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: def main() return {a:1, b:2} syntax error\n",
      "\n",
      "Top 5 most similar questions in corpus:\n",
      "1)  multiple return statements in python \"def\" causes syntax error (Score: 0.5843)\n",
      "2)  Why use def main()? (Score: 0.5332)\n",
      "3)  Why no compiler error for main() without a return at the end? (Score: 0.5297)\n",
      "4)  Help calling def from class (Score: 0.4954)\n",
      "5)  Why is \"def InvalidArgsSpecified:\" a syntax error? (Score: 0.4925)\n",
      "CPU times: user 3.59 s, sys: 1.13 s, total: 4.71 s\n",
      "Wall time: 2.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query = 'def main() return {a:1, b:2} syntax error'\n",
    "result = final_fun_1(query)\n",
    "print(\"Query:\", query)\n",
    "display_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a4772af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: import KNN                        knn= KNN(n=4)                        knn.fit(Xtrain, ytrain)\n",
      "\n",
      "Top 5 most similar questions in corpus:\n",
      "1)  How to import * with __import__ (Score: 0.5479)\n",
      "2)  implemention of imports (Score: 0.5137)\n",
      "3)  What exactly does \"import *\" import? (Score: 0.4964)\n",
      "4)  Python import mechanics (Score: 0.4852)\n",
      "5)  import os to j2me (Score: 0.4848)\n",
      "CPU times: user 3.63 s, sys: 1.15 s, total: 4.79 s\n",
      "Wall time: 2.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query ='import KNN \\\n",
    "                       knn= KNN(n=4) \\\n",
    "                       knn.fit(Xtrain, ytrain)'\n",
    "result = final_fun_1(query)\n",
    "print(\"Query:\", query)\n",
    "display_result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01c6463",
   "metadata": {},
   "source": [
    "### Inference:\n",
    "\n",
    "- Results seems satisfactory for almost all queries.\n",
    "- For code related queries: <br>\n",
    "    1) try-except query: it captured and understood code, thus result set includes questions related to exception code.<br>\n",
    "    2) main function query: It captured essence of main function in programming language.<br>\n",
    "    3) KNN query: It was not able to capture fully that code is related to KNN algorithm yet it yield results related to import statement.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
