{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1\n",
    "\n",
    "### **0.5* Sbert_cosine_sim + 0.3* W2v_cosine_sim + 0.2* Normalized_Score**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On following basis weight selection hase been done:-\n",
    "- Sbert gave best results among all so more weightage is given.\n",
    "- Custom w2v is trained on this data so certaily it provides some value, so 0.3 weightage has been given.\n",
    "- Higher the question score, more likely to be answered or can contain more answers, so 0.2 weightage has been assigned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import bs4\n",
    "import swifter\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import Word2Vec\n",
    "import joblib\n",
    "from tqdm import tqdm \n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and embedding fucntions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/a/47091490/4084039\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    #phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "\n",
    "\n",
    "def text_preprocessing(text):\n",
    "    '''This function does text preprocessing \n",
    "       It includes removal of html tags,\n",
    "       converting to lowercase, \n",
    "       decontraction and \n",
    "       removal of any non alphanumeric characters.\n",
    "       \n",
    "       Function takes one parameter - text\n",
    "       returns - preprocessed text\n",
    "    '''\n",
    "    \n",
    "    # Some titles (~42) start with '<' but doesnt have closing '>'. \n",
    "    #eg: #text = '<asp: RegularExpressionValidator and RegexOptions.IgnorePatternWhitespace'\n",
    "    # beautifulsoup gives emppty string on such text so remove '<' before removing html tags from titles.\n",
    "    text = text.replace(\"<\",\"\")\n",
    "    # Remove html tags from question corpus\n",
    "    text = bs4.BeautifulSoup(text, 'lxml').get_text()\n",
    "    # Convert each word to lowercase\n",
    "    text = text.lower()\n",
    "    # text decontraction. eg: won't to will not. Can't to cannot\n",
    "    text = decontracted(text)\n",
    "    # Remove any non-alphanumeric characters if present\n",
    "    #text = re.sub('\\W', ' ',text).strip()\n",
    "    text = re.sub(\"[^a-zA-Z'.+# ]+\", '', text) # kepping + for c++, . for .net, vb.net etc, # for C#\n",
    "\n",
    "    # why lemmatization is choose over stemming\n",
    "    #https://stackoverflow.com/questions/1787110/what-is-the-difference-between-lemmatization-vs-stemming\n",
    "    # Lemmatization   \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "def get_w2v_embedding(sentence):\n",
    "    '''Get 300 dim word embedding for each word from custom trained w2v model.\n",
    "       Avg word embedding to create sentence embedding\n",
    "       \n",
    "       Function accepts only one parameter - sentence (text input)\n",
    "       returns - 300 dim sentence embedding'''\n",
    "    \n",
    "    custom_w2v = []\n",
    "    for word in sentence.split():\n",
    "        if (word not in final_stopwords):\n",
    "            try:\n",
    "                custom_w2v.append(loaded_model.wv[word])#keyerror\n",
    "            except:\n",
    "                pass\n",
    "         \n",
    "    avg_w2v = np.array(custom_w2v).mean(axis=0)\n",
    "    return avg_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stopwords = joblib.load('final_stopwords.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999348, 3)\n",
      "CPU times: user 370 ms, sys: 215 ms, total: 586 ms\n",
      "Wall time: 1.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = joblib.load('cleaned_df.pkl')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.7 s, sys: 3.53 s, total: 41.3 s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loaded_model = Word2Vec.load(\"model/custom_trained_w2v/word2vec_v2.model\")\n",
    "sentence_embedder = joblib.load('sentence_embedder.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained embedding loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 759 ms, sys: 2.61 s, total: 3.37 s\n",
      "Wall time: 22.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v_embeddings = joblib.load('w2v_embeddings.pkl')\n",
    "sbert_embeddings = joblib.load('sbert_embeddings.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to retrieve semantically similar questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_questions(query):\n",
    "    ''' Function to accept user query and show top 5 similar question alongwith custom score.\n",
    "        Function accepts one parameter: query (text input)\n",
    "        Processing: Text preprocessing of query, \n",
    "                    compute sentence embedding with avg w2v and sbert method,\n",
    "                    compute custom weighted score with formula 0.5*Sbert_cosine_sim + 0.3*W2v_cosine_sim + 0.2*Normalized_Score\n",
    "        Returns: None, prints similar question's titles and custom score obtained.\n",
    "    '''\n",
    "    preprocessed_query = text_preprocessing(query)\n",
    "    \n",
    "    query_embedding_w2v = get_w2v_embedding(preprocessed_query)\n",
    "\n",
    "    query_embedding_sbert = sentence_embedder.encode(preprocessed_query, convert_to_tensor=True)\n",
    "\n",
    "    \n",
    "    # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "    df['Sbert_cosine_sim'] = util.pytorch_cos_sim(query_embedding_sbert, sbert_embeddings)[0]\n",
    "    df['W2v_cosine_sim'] = cosine_similarity(np.array(query_embedding_w2v).reshape(1, -1),np.array(w2v_embeddings)).T\n",
    "\n",
    "    df['Final_Score'] = (0.5*df['Sbert_cosine_sim']) + (0.3*df['W2v_cosine_sim']) + (0.2*df['Normalized_Score'])\n",
    "    # Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "    top_k = 5\n",
    "    \n",
    "    top_results = torch.topk(torch.tensor(df['Final_Score'].values), k=top_k)\n",
    "\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar questions in corpus:\")\n",
    "    \n",
    "    i = 1\n",
    "    for score, idx in zip(top_results[0], top_results[1]):\n",
    "        print(\"{}) \".format(i), df['Title'].iloc[int(idx)], \"(Score: {:.4f})\".format(score))\n",
    "        i = i+1\n",
    "        \n",
    "#     Sorting using below function also took almost same time, difference of around 0.6 seconds was noticed\n",
    "\n",
    "#     df.sort_values(by='Final_Score', ascending=False, inplace=True)\n",
    "#     print(df[['Title','Final_Score']].head().values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: python sort dictionary\n",
      "\n",
      "Top 5 most similar questions in corpus:\n",
      "1)  Python: sort this dictionary (dict in dict) (Score: 0.7410)\n",
      "2)  sort a dictionary according to their values in python (Score: 0.7297)\n",
      "3)  Sort by key of dictionary inside a dictionary in Python (Score: 0.7258)\n",
      "4)  Sorting dictionary keys in python (Score: 0.7206)\n",
      "5)  Dictionary sort? (Score: 0.7203)\n",
      "CPU times: user 3.17 s, sys: 981 ms, total: 4.15 s\n",
      "Wall time: 2.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "get_similar_questions('python sort dictionary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: CSS Performance\n",
      "\n",
      "Top 5 most similar questions in corpus:\n",
      "1)  CSS Performance (Score: 0.8013)\n",
      "2)  CSS Performance (Score: 0.8013)\n",
      "3)  CSS Performance Question (Score: 0.7134)\n",
      "4)  CSS Performance issues (Score: 0.7092)\n",
      "5)  Performance, serve all CSS at once, or as its needed? (Score: 0.6370)\n",
      "CPU times: user 3.23 s, sys: 1.1 s, total: 4.32 s\n",
      "Wall time: 2.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "get_similar_questions('CSS Performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: python convert date to datetime\n",
      "\n",
      "Top 5 most similar questions in corpus:\n",
      "1)  Convert date to datetime in Python (Score: 0.7912)\n",
      "2)  Convert date Python (Score: 0.7282)\n",
      "3)  How can I convert the time in a datetime string from 24:00 to 00:00 in Python? (Score: 0.7097)\n",
      "4)  Date converter in python (Score: 0.6901)\n",
      "5)  How do I get datetime from date object python? (Score: 0.6845)\n",
      "CPU times: user 2.95 s, sys: 935 ms, total: 3.88 s\n",
      "Wall time: 2.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "get_similar_questions('python convert date to datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: how to create list of lists in python\n",
      "\n",
      "Top 5 most similar questions in corpus:\n",
      "1)  Creating lists of lists in a pythonic way (Score: 0.7286)\n",
      "2)  How can I make a list in Python like (0,6,12, .. 144)? (Score: 0.7019)\n",
      "3)  List of Lists in python? (Score: 0.7016)\n",
      "4)  How to create nested lists in python? (Score: 0.7003)\n",
      "5)  Creating a list of objects in Python (Score: 0.6929)\n",
      "CPU times: user 3.08 s, sys: 1.13 s, total: 4.21 s\n",
      "Wall time: 2.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "get_similar_questions('how to create list of lists in python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: pd.melt() not working python\n",
      "\n",
      "Top 5 most similar questions in corpus:\n",
      "1)  I am getting an error when trying to use melt() on a dataframe containing Dates (Score: 0.4897)\n",
      "2)  Running Panda3D on Python 2.6 (Score: 0.4865)\n",
      "3)  Python .pth Files Aren't Working (Score: 0.4837)\n",
      "4)  Python pdb not breaking in files properly? (Score: 0.4795)\n",
      "5)  Python optparse not working for me (Score: 0.4749)\n",
      "CPU times: user 2.98 s, sys: 1.07 s, total: 4.05 s\n",
      "Wall time: 2.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "get_similar_questions('pd.melt() not working python')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: try: 22/0 except Exception as e:print(\"Error! Code: {c}, Message, {m}\".format(c = e.code, m = str(e))\n",
      "\n",
      "Top 5 most similar questions in corpus:\n",
      "1)  Exception message (Python 2.6) (Score: 0.5633)\n",
      "2)  Format Exception error (Score: 0.5628)\n",
      "3)  Exception Error in the Code (Score: 0.5612)\n",
      "4)  complus Exception code -532462766 (Score: 0.5557)\n",
      "5)  uncatchable exception from unreachable code (Score: 0.5432)\n",
      "CPU times: user 3.25 s, sys: 1.06 s, total: 4.31 s\n",
      "Wall time: 2.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "get_similar_questions('try: 22/0 except Exception as e:print(\"Error! Code: {c}, Message, {m}\".format(c = e.code, m = str(e))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: def main() return {a:1, b:2} syntax error\n",
      "\n",
      "Top 5 most similar questions in corpus:\n",
      "1)  multiple return statements in python \"def\" causes syntax error (Score: 0.5843)\n",
      "2)  Why use def main()? (Score: 0.5332)\n",
      "3)  Why no compiler error for main() without a return at the end? (Score: 0.5297)\n",
      "4)  Help calling def from class (Score: 0.4954)\n",
      "5)  Why is \"def InvalidArgsSpecified:\" a syntax error? (Score: 0.4925)\n",
      "CPU times: user 3.39 s, sys: 1.03 s, total: 4.42 s\n",
      "Wall time: 2.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "get_similar_questions('def main() return {a:1, b:2} syntax error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: import KNN                        knn= KNN(n=4)                        knn.fit(Xtrain, ytrain)\n",
      "\n",
      "Top 5 most similar questions in corpus:\n",
      "1)  How to import * with __import__ (Score: 0.5479)\n",
      "2)  implemention of imports (Score: 0.5137)\n",
      "3)  What exactly does \"import *\" import? (Score: 0.4964)\n",
      "4)  Python import mechanics (Score: 0.4852)\n",
      "5)  import os to j2me (Score: 0.4848)\n",
      "CPU times: user 3.02 s, sys: 990 ms, total: 4.01 s\n",
      "Wall time: 2.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "get_similar_questions('import KNN \\\n",
    "                       knn= KNN(n=4) \\\n",
    "                       knn.fit(Xtrain, ytrain)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference:\n",
    "\n",
    "- Results seems satisfactory for almost all queries.\n",
    "- For code related queries: <br>\n",
    "    1) try-except query: it captured and understood code, thus result set includes questions related to exception code.<br>\n",
    "    2) main function query: It captured essence of main function in programming language.<br>\n",
    "    3) KNN query: It was not able to capture fully that code is related to KNN algorithm yet it yield results related to import statement.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
